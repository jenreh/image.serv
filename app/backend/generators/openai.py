import base64
import logging
from typing import Final

import anyio
import httpx
from openai import AsyncAzureOpenAI

from app.backend.models import (
    EditImageInput,
    GenerationInput,
    ImageGenerator,
    ImageGeneratorResponse,
    ImageResponseState,
)

logger = logging.getLogger(__name__)

TMP_IMG_FILE: Final[str] = "gpt-image"


class OpenAIImageGenerator(ImageGenerator):
    """Generator for the OpenAI DALL-E API."""

    def __init__(
        self,
        api_key: str,
        id: str = "gpt-image-1",  # noqa: A002
        label: str = "OpenAI GPT-Image-1",
        model: str = "gpt-image-1",
        backend_server: str | None = None,
        base_url: str | None = None,
    ) -> None:
        super().__init__(
            id=id,
            label=label,
            model=model,
            api_key=api_key,
            backend_server=backend_server,
        )
        # self.client = AsyncOpenAI(api_key=self.api_key)

        self.client = AsyncAzureOpenAI(
            api_version="2025-04-01-preview",
            azure_endpoint=base_url,
            api_key=api_key,
        )

    async def _enhance_prompt(self, prompt: str) -> str:
        response = await self.client.chat.completions.create(
            model="gpt-4.1-mini",
            stream=False,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are an image generation assistant specialized in "
                        "optimizing user prompts. Ensure content "
                        "compliance rules are followed. Do not ask followup "
                        "questions, just generate the optimized prompt."
                    ),
                },
                {
                    "role": "user",
                    "content": f"Enhance this prompt for image generation: {prompt}",
                },
            ],
        )

        result = response.choices[0].message.content.strip()
        if not result:
            result = prompt

        logger.debug("Enhanced prompt for image generation: %s", result)
        return result

    async def _perform_generation(
        self, input_data: GenerationInput
    ) -> ImageGeneratorResponse:
        """Generate images using gpt-image-1 model."""
        prompt = self._format_prompt(input_data.prompt, input_data.negative_prompt)

        if input_data.enhance_prompt:
            prompt = await self._enhance_prompt(prompt)

        response = await self.client.images.generate(
            model=self.model,
            prompt=prompt,
            n=input_data.n,
            size=input_data.size,
            quality=input_data.quality,
            moderation=input_data.moderation,
            output_format=input_data.output_format,
            output_compression=input_data.output_compression,
            background=input_data.background,
        )

        self.clean_tmp_path(TMP_IMG_FILE)

        images = []
        # gpt-image-1 always returns base64
        for img in response.data:
            if img.b64_json:
                image_bytes = base64.b64decode(img.b64_json)
                image_url = await self._save_image_to_tmp_and_get_url(
                    image_bytes=image_bytes,
                    tmp_file_prefix=TMP_IMG_FILE,
                    output_format=input_data.output_format,
                )
                images.append(image_url)

        if not images:
            logger.error("No images were generated by OpenAI")
            return ImageGeneratorResponse(
                state=ImageResponseState.FAILED,
                images=[],
                error="No images were generated",
            )

        return ImageGeneratorResponse(state=ImageResponseState.SUCCEEDED, images=images)

    async def _load_image(self, path: str) -> bytes:
        """Load image from URL, file path, or base64 data URL."""
        if path.startswith("data:image"):
            # Decode base64 data URL
            logger.debug("Decoding base64 data URL")
            base64_data = path.split(",", 1)[1]
            return base64.b64decode(base64_data)

        if path.startswith(("http://", "https://")):
            # Download from URL
            logger.debug("Downloading image from URL: %s", path)
            async with httpx.AsyncClient() as client:
                response = await client.get(path)
                response.raise_for_status()
                return response.content

        # Read from local file
        logger.debug("Reading image from file: %s", path)
        async with await anyio.open_file(path, "rb") as f:
            return await f.read()

    async def _perform_edit(self, input_data: EditImageInput) -> ImageGeneratorResponse:
        """Edit images using gpt-image-1 model."""

        # Load image files (supports up to 16 images)
        image_files = []
        for img_path in input_data.image_paths:
            image_bytes = await self._load_image(img_path)
            image_files.append(image_bytes)

        logger.info("Loaded %d images for editing", len(image_files))

        # Load mask if provided
        mask_file = None
        if input_data.mask_path:
            mask_file = await self._load_image(input_data.mask_path)
            logger.debug("Loaded mask image")

        prompt = self._format_prompt(input_data.prompt, input_data.negative_prompt)

        # Call gpt-image-1 edit API
        response = await self.client.images.edit(
            model=self.model,
            image=image_files,
            prompt=prompt,
            mask=mask_file,
            n=input_data.n,
            size=input_data.size,
            quality=input_data.quality,
            output_format=input_data.output_format,
            output_compression=input_data.output_compression,
            input_fidelity=input_data.input_fidelity,
            background=input_data.background,
        )

        self.clean_tmp_path(TMP_IMG_FILE)

        images = []
        # gpt-image-1 always returns base64
        for img in response.data:
            if img.b64_json:
                image_bytes = base64.b64decode(img.b64_json)
                image_url = await self._save_image_to_tmp_and_get_url(
                    image_bytes=image_bytes,
                    tmp_file_prefix=TMP_IMG_FILE,
                    output_format=input_data.output_format,
                )
                images.append(image_url)

        logger.info("Successfully edited %d images", len(images))
        return ImageGeneratorResponse(state=ImageResponseState.SUCCEEDED, images=images)
